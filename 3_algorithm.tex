\section{Bisection and Twisted Algorithm}
\label{sec:algorithm}
For an arbitrary matrix $A\in R^{m \times n} (m>n)$ all SVD algorithms discussed in section \ref{sec:intro} consist of two steps:
The first step is to reduce the initial matrix $A$ to bidiagonal form using Householder transformation.
The second step is to reduce the bidiagonal matrix into a diagonal matrix.

By applying the Householder transformation, we can decompose the matrix $A$ as follows:
\begin{equation}
\label{H-transform}
A = Q B P^T ,
\end{equation}
where $B \in R^{m \times n}$ is a bidiagonal matrix of the following form:
\begin{equation}
B = \left( \begin{array}{c}
      B_1 \\
      0  
\end{array} \right) 
\end{equation}
Here $B_1 \in R^{n \times n}$ is a bidiagonal matrix. Since 
\[
B^T B = \left( \begin{array}{cc }B_1^T & 0 \end{array} \right) \left( \begin{array}{c} B_1 \\ 0  \end{array} \right) = B_1^T B_1,
\]
we assume, without loss of generality, that $B$ is a $n \times n$ bidiagonal matrix in this paper.
 
Since Householder transform has been fully optimized in paper \cite{LiuHouseholder}.
In this paper, we focus only on the second step that reduces a bidiagonal matrix to a diagonal matrix, for which the  ``bisection and twisted'' algorithm is designed.

The bisection and twisted algorithm is divided into two phases:
(1) obtain the singular values of the bidiagonal matrix by using bisection approach; and
(2) obtain the corresponding left and right singular vectors of every singular value by using twisted factorization.
Next we illustrate these two phases in the following subsections.

\subsection{Bisection Algorithm}
%Bisection algorithm is widely used in many applications to find the roots of a sophisticated equation that cannot be solved directly.
%It repeatedly bisects an interval and then selects a subinterval in which a root lies for further processing until convergence.
%Bisection is an approximation algorithm for solving sophisticated equation and can reach certain relative accuracy solution.

Suppose $B$ is an upper bidiagonal $n \times n$ matrix with elements $b_{i,j}$ reduced by Householder transform \cite{10householder}.
The matrix $T = B^T B - \mu^2 I_n$ can be decomposed as
\begin{equation}
\label{eq:T}
T = B^T B - \mu^2 I_n = L D L^T ,
\end{equation}
where $\mu$ is a shift variable, $D$ is $diag(d_{1}, \cdots, d_{n})$, and 
%\[ D =  \left( \begin{array}{cccc}
%d_{1} & 0     & \cdots & 0 \\
%0     & d_{2} & \cdots & 0 \\
%\vdots& \vdots& \ddots & \vdots \\
%    0 & 0     & \cdots & d_{n} \end{array} \right),
\begin{equation}
 L =  \left( \begin{array}{ccccc}
     1&      &       &        &  \\
 l_{1}& 1    &       & 0      &  \\
      & l_{2}& \ddots&        &  \\
      & 0    & \ddots& \ddots &  \\
      &      &       & l_{n-1}& 1
\end{array} \right) .
\label{eq:l}
\end{equation}
By substituting $L$ and $D$ into Eq. (\ref{eq:T}), we can obtain the following equations
\begin{equation}
\left \{
\begin{aligned}
b_{1,1}^2 - \mu^2 &= d_1\\
b_{k-1,k-1} b_{k-1,k} &= d_{k-1} l_{k-1}\\
b_{k-1,k}^2 + b_{k,k}^2 - \mu^2 &= l_{k-1}^2 d_{k-1} + d_k
\end{aligned}
\right .
\label{eq:ldl}
\end{equation}
where $k = 2,3,\cdots,n$.
Next, we define an auxiliary values $t_{k}$ as
\begin{equation}
t_{k} = t_{k-1} * (b_{k-1,k}^2 / d) - \mu^2 ,
\label{eq:tmp}
\end{equation}
and then all the equations in Eq. (\ref{eq:ldl}) reduce to
\begin{equation}
\left \{
\begin{aligned}
d_1 = b_{1,1}^2 - \mu^2 \\
d_k = b_{k,k}^2 + t_{k}
\end{aligned}
\right .
\label{eq:negcount}
\end{equation}

It is clear that matrices $D$ and $T$ are two congruent symmetric matrices.
According to the Sylvester's law of inertia, both matrices $D$ and $T$ have the same numbers of positive, negative, and zero eigenvalues.
We define a function denoted by $NegCount(\mu)$ to count the number of negative eigenvalues of matrix $T$.
Algorithm \ref{alg:negcount} describes how $NegCount$ function works.
%Variable initialization is in Line 2. 
Lines 3-7 calculate the negative number of singular values that are less than $\mu$.
%Line 3-9 calculate the negative number of singular values that are less than $\mu$.
%In order to count the number of negative eigenvalues of matrix $T$, we define a function known as  $NegCount(\mu)$.
%$NegCount(\mu)$ is the core idea for bisection, and will be used to bisect the interval of solutions in Algorithm \ref{alg:bisection}.
Since matrices $B$ and $B^T$ have the same singular values,
$NegCount(\mu)$ is the number of the singular values of $B$ which are less than $\mu$.
It is clear that if the floating point arithmetic is monotonic, then $NegCount(x)$ is a monotonically non-decreasing function of $x$\cite{95ETNAbisecion}.
\input{algorithm_negcount}

%Algorithm \ref{alg:negcount} is used to count the number of singular values of matrix $B$ those are less than $\mu$.
%From the algorithm, the number of singular values in an arbitrary interval $[\mu_1,\mu_2)$ are $c_{\mu_2} - c_{\mu_1}$.
Algorithm \ref{alg:bisection} is the bisection algorithm for calculating the singular values in interval $[l,u)$. Based on the definition of $NegCount$ the total number of singular values in $[l,u)$ is $n_u - n_l = NegCount(u) - NegCount(l)$.
Lines 5-17 can be parallelized in bisection algorithm.
%In our implementation, we parallelize Line 5-17 of the bisection algorithm. 
\input{algorithm_bisection}
%\textcolor{blue}{
%The basic steps of Algorithm \ref{alg:bisection} are as follows:
%\begin{enumerate}
%\item Check whether singular values are in interval (Line 2-4);
%\item Put the interval into Worklist (Line 5);
%\item Check Worklist is non-empty, load subinterval from Worklist (Line 6-7);
%\item If the subinterval are convergence, save singular values (Line 9-11);
%\item Else bisect one interval containing singular values into two subintervals (Line 13);
%\item Call $NegCount$ algorithm to get the number of singular values in subintervals (Line 14).
%\item Select the subinterval(s) which contain singular values for further bisection (Line 16-21).
%\item Repeat 3-7 until all subintervals are sufficiently small.
% which means the left border and right border of the subintervals are almost equal to each other.
%\item The singular values are considered as the midpoint of the subintervals.
%\end{enumerate}
%I want to delete it.
%}


\subsubsection{Weak Data Dependency of Bisection Algorithm}
~

%In this section, we will prove why the data dependence of bisection algorithm is weak.
%Since the singular values are all positive, we suppose that the boundary containing all the singular values is $[0, ug)$.
%$ug$ can be calculated by Gershgorin circle theorem\cite{gershgorin}.
The efficiency of our algorithm is based on the assumption that the data dependencies for both separating and calculating phases are weak so that we could divide the big problem into smaller but loosely coupled components. Since the singular values are all positive, we assume that the boundary containing all the singular values is $[0, ug)$, where the upper bound $ug$ can be calculated by Gershgorin circle theorem\cite{gershgorin}.

%After obtaining the boundary, we separate the boundary $[0,ug)$ into $p$ subintervals, and each subinterval $[l_i,u_i)$ can be calculates 
%\begin{eqnarray}
%l_i &=& (ug/p) * (i-1)\\
%u_i &=& (ug/p) * i 
%\end{eqnarray}
%where $i = 1, 2, \cdots, p$. In the subinterval of $[l_i,u_i)$, we can calculate the number of singular values that are less than $l_i$ and $u_i$, separately.
%\begin{eqnarray}
% n_{l_i} = NegCount(l_i) \\
% n_{u_i} = NegCount(u_i)
%\end{eqnarray}
%The number of singular values between $[l_i,u_i)$ is $n_{u_i} - n_{l_i}$, and the indices of the singular values are $n_l, n_l+1, ..., n_u-1$.
%It shows that the data dependence is weak in separating phase.
After obtaining the boundary, we divide the interval $[0,ug)$ into $p$ subintervals, and each subinterval $[l_i,u_i)$ can be calculated as follows:
\begin{eqnarray}
l_i &=& (ug/p) * (i-1)\\
u_i &=& (ug/p) * i ,
\end{eqnarray}
where $i = 1, 2, \cdots, p$. Then we can calculate the numbers of singular values $n_{l_i}$ and $n_{u_i}$ that are less than $l_i$ and $u_i$ as follows, respectively:
\begin{eqnarray}
 n_{l_i} = NegCount(l_i) \\
 n_{u_i} = NegCount(u_i) .
\end{eqnarray}
It is easily seen that the number of singular values in interval $[l_i,u_i)$ is $n_{u_i} - n_{l_i}$ and the indices of these singular values are $n_l, n_l+1, ..., n_u-1$. 
We thus illustrate that the data dependence is weak when dividing the interval
to subintervals.

%Next, we show in calculating phase, the bisection algorithm is also weak data dependence.
%Suppose $[l,u)$ is an subinterval containing several singular values of a matrix.
%$n_l$ and $n_u$ are the numbers of singular values that are less than $l$ and $u$, separately. 
%How is bisection algorithm able calculate an arbitrary singular value $v$ with index $(n_l+k)$ in an subinterval $[l,u)$?
%After several times' bisection iteration, the subinterval $[l,u)$ reduces to $[v_1,v_1+\tau)$, whose $Necount$ are $(n_l+k-1)$ and $(n_l+k)$, separately.
%$v$ is in the subinterval $[v_1,v_1+\tau)$. if $\tau$ is small enough, we can recognize $v1$ is equal to $v$. Thus, $v1$ is the singular value with index $(n_l+k)$.
%The total procedure of bisection algorithm only require $NegCount$ function.
%They do not need the information of other singular values.
Now, we show that the data dependency in bisection algorithm is also weak in the calculation phase (Algorithm \ref{alg:bisection}).
Suppose $[l,u)$ is an subinterval containing several singular values of a matrix.
$n_l$ and $n_u$ are the numbers of singular values that are less than $l$ and $u$, respectively.
How is the bisection algorithm able to calculate an arbitrary singular value $v$ with index $(n_l+k)$ in an subinterval $[l,u)$?
After several bisection iterations, the subinterval $[l,u)$ reduces to $[v_1,v_1+\tau)$, whose $NegCount$ are $(n_l+k-1)$ and $(n_l+k)$, respectively.
Since $v$ is in the subinterval $[v_1,v_1+\tau)$, we know that $| v_1 - v | < \tau$, and if $\tau$ is small enough, we stop the iteration and take $v_1$ as calculated singular value with index $(n_l+k)$.
The whole procedure of bisection algorithm requires only $NegCount$ function without the information of other singular values.

%We want to obtain the $(n_l+k)$-th ($k< n_u-n_l$) singular value in interval $[l,u)$.
%After we make use of bisection algorithm above, $m=(l+u)/2$ is considered to be the singular value(s) of matrix $B$ with multiplicity $r=n_u-n_l$ with error less than $\tau/2$ from the actual values. The indices of singular values in that interval is $(n_l+k) \to (n_l+k+r-1)$.That is
%\begin{eqnarray}
% v_{n_l+k} = \cdots = v_{n_l+k+r-1} = m.
%\end{eqnarray}
%Also, $n_l+k-1$ singular values are less than $v_{n_l+k}$, and $n-(n_l+k+r-1)$ singular values are larger than $v_{n_l+k}$. 
%Bisection algorithm is able to calculate the singular value without any information of other singular values.
%\textcolor{blue}{This is why the data dependence of bisection algorithm is weak.}
%After using $n$ times of bisection algorithm with different index $j\;\; (j=1,2,\cdots,n)$ in serial. we can obtain all singular values in an increasing sequence. 
%\[ v_{j} \le v_{j+1} \]

%The interval containing all the singular values can be calculated by Gershgorin circle theorem\cite{gershgorin}.
%In the algorithm, $MidPoint$ should avoid the possibility of overflow or underflow.

\subsubsection{Error Analysis}
~

In theory, the bisection algorithm is bound to the upper limit of error between actual value and calculating value, which can be set according to particular applications. 
The selection of an error tolerance $\tau$ greatly impacts the execution time of the algorithm. 
Large error tolerance will allow us to solve the problem quick but result in low accuracy.
On the other hand, too small value for $\tau$ may fail to reach the required accuracy.
%Large error tolerance may solve the problem quick but result in low accuracy. 
%If the tolerance of error $\tau$ is too large, the algorithm may obtain the singular values with relatively low accuracy, but the execution time may be faster due to the smaller number of iterations.
%However, if we choose a too small value for $\tau$, the computation may not reach the required accuracy.
Based on our tests, we can obtain the singular values with error tolerance less than $10^{-18}$.
%, this is good enough for most of the applications \textcolor{red}{(do we have any references?)}.

\subsection{Twisted Algorithm}

The second phase of our algorithm, twisted algorithm, calculates the corresponding left and right singular vectors.
It has advantages over existing approaches such as the power method\cite{08power}, which can only find the largest singular value and the corresponding singular vector, and inverse iteration\cite{11iterative}, which does not guarantee the accuracy and orthognality of the singular vectors when the singular values are clustered. In contrast, the twisted algorithm \cite{09NLAAtwisted} can calculate  orthogonal singular vectors with adequate accuracy. 
%The simplest method to obtain the singular vectors is the power method\cite{08power}. The limitation is that it can find only the largest singular value and the corresponding singular vector.
%Inverse iteration\cite{11iterative} is another approach for the singular vectors but it doesn't guarantee the accuracy and orthognality of the singular vectors when the singular values are clustered.
%Moreover, the inverse iteration requires time complexity of $O(n^3)$ to obtain all the singular vectors.

%To address these issues, we utilize the improved twisted factorization to calculate the singular vectors.
%The algorithm can address the accurate or orthogonal problems in general bisection and inversed algorithm.
%It can also solve the singular vectors whose singular values are clustered together.
Suppose $\lambda$ is a singular value of bidiagonal matrix $B \in R^{n \times n}$.
Then the matrix $B^T B - \lambda^2 I$ can be decomposed as
\begin{equation}
B^T B - \lambda^2 I_n = L D_L L^T = U D_U U^T ,
\end{equation}
where $D_L=diag(\alpha_1, \cdots, \alpha_n)$, $D_U = diag(\beta_1, \cdots, \beta_n)$. Matrix $L$ is the same form as in Eq. (\ref{eq:l})
%\[ L =  \left( \begin{array}{ccccc}
%     1&      &       &        &  \\
% l_{1}& 1    &       & 0      &  \\
%      & l_{2}& \ddots&        &  \\
%      & 0    & \ddots& \ddots &  \\
%      &      &       & l_{n-1}& 1
%\end{array} \right),
\begin{equation}
 U =  \left( \begin{array}{ccccc}
  1 & u_{1}&       &       &  \\
    & 1    & u_{2} & 0     &  \\
    &      & 1     & \ddots&  \\
    & 0    &       & \ddots& u_{n-1} \\
    &      &       &       & 1
 \end{array} \right)
\end{equation}
%$L$ is left bidiagonal matrix, $U$ is upper bidiagonal matrix.
%The diagonal elements in $L$ and $U$ are 1s.
%The subdiagonal elements are $l_k$ in $L$, and the superdiagonal elements are $u_k$ in $U$, separately.

Given the $LDL^T$ and $UDU^T$ decomposition, the twisted factorization of the shifted matrix is shown as
\begin{equation}
B^T B - \lambda^2 I = N_k D_k N_k^T ,
\label{eq:twisted}
\end{equation}
where $k$ is the index of the minimum $\gamma$ defined in Eq. (\ref{eq:gamma}).
\begin{equation}
\label{eq:gamma}
k = \arg \min_{1\le i \le n} \gamma_{i} =
\begin{cases}
\beta_1 & \text{if } i=1 \\
\beta_i - \alpha_i * l_{i-1} & \text{if } 2\le i\le n-1\\
\alpha_n & \text{if } i=n
\end{cases}
\end{equation}
$D_k$ is diagonal matrix, $N_k$ is the twisted matrix with form 
\begin{equation}
N_k =  \left( \begin{array}{cccccccc}
 1& & & & & & & \\
 l_{1}& \ddots& & & & 0& & \\
 & \ddots& 1& & & & &  \\
 & & l_{k-2}& 1 & & & & \\
 & & & \eta_k& 1& u_k& & \\
 & & & & & 1& \ddots& \\
 & & 0& & & & \ddots& u_{n-1}\\
 & & & & & & & 1 \end{array} \right)
\end{equation}
\begin{equation}
\eta_k = \begin{cases}
0 & \text{if } i=1 \\
\frac{l_{k-1}\alpha_{k-1}}{(\alpha_{k-1} - v_{k-1}^2 \beta_{k+1})} & \text{if } 2\le i\le n-1\\
\l_{n-1} & \text{if } i=n
\end{cases}
\end{equation}

Thus, the corresponding singular vector of $\lambda$ can be obtained by solving the following matrix equations and then normalizing the solution:
\begin{equation}
\label{eq:unnorm}
N_k^T Z_k = E_k ,
\end{equation}
 where each column in matrix $Z_k$ is the non-normalization solution of singular vector corresponding to $\lambda$, and $E_k$ is a unitary matrix.

One advantage of BT algorithm is that it can be applied to cases where singular values are clustered together.
%\textcolor{red}{
Suppose $m$ is the multiplicity of singular values of matrix $B$. 
The algorithm selects the indices of the first $m$ minimum values of $\gamma$. %(May need some more clarification????)} 
Each index $k$ in $m$ has a different twisted factorization, and thus the singular vector can be obtained by solving its own Eq. (\ref{eq:unnorm}). These singular vectors are also orthogonal to each others\cite{09NLAAtwisted}.
\input{algorithm_twisted}
Algorithm \ref{alg:twisted} is the algorithm to obtain the corresponding singular vectors of given singular values.
Lines 4-7 are two obtain the parameter $\gamma$.
Obtain the multiplicity of a singular value and their corresponding minimum values are described in Lines 8-9.
Lines 10-16 are to calculate the singular vectors and normalize them.
%We completely parallelize the twisted factorization to speed up the algorithm on GPU architecture.
The cost for every singular vector transformation is $O(n)$, and the total cost of the transformations is $O(n^2)$.

