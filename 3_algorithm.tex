\vspace{-0.1in}
\section{Bisection and Twisted Algorithm} \label{sec:algorithm}
\vspace{-0.1in}
For an arbitrary matrix $A\in \mathbb{R}^{m \times n} (m>n)$, 
A SVD of an arbitrary matrix $A\in \mathbb{R}^{m \times n} (m>n)$ is the form $A = U \Sigma V^T$, where $U$ is a $m \times m$ orthogonal matrix, $V$ is a $n\times n$ orthogonal matrix, and $\Sigma$ is a $m\times n$ diagonal matrix.
A typical SVD algorithm can be broken down into two steps \cite{65SIAM}.
The first step is to reduce the initial matrix to bidiagonal by Householder transform.
The second step is to diagonalize the bidiagonal matrix.
Householder transform above has been optimized in paper \cite{LiuHouseholder} for small matrices. For very large matrices, it is still an open problem. 
In this paper, we focus only on the second step that reduces a bidiagonal matrix to a diagonal matrix, for which the  ``bisection and twisted'' algorithm is designed.

%\begin{equation}
%A = Q B P^T
%\label{eq:householder}
%\end{equation}
%where $B \in \mathbb{R}^{m \times n}$ is a bidiagonal matrix of the form $ B = ( B_1, 0 )^T$.
%Here $B_1 \in \mathbb{R}^{n \times n}$ is a bidiagonal matrix. 
%Since $B^T B = (B_1^T, 0)(B_1, 0)^T = B_1^T B_1$,
%we assume, without loss of generality, that $B$ is a $n \times n$ bidiagonal matrix in this paper.
 
The bisection and twisted algorithm is divided into two phases:
(1) obtain the singular values of the bidiagonal matrix by bisection approach; and
(2) obtain the corresponding left and right singular vectors of every singular value by twisted factorization.
Next we describe these two phases in the following subsections.

\vspace{-0.1in}
\subsection{Bisection Algorithm}\label{subsec:bisection}
\vspace{-0.1in}
Suppose $B$ is an upper bidiagonal $n \times n$ matrix with elements $b_{i,j}$ reduced by Householder transform \cite{10householder}.
The matrix $T = B^T B - \mu^2 I_n$ can be decomposed as
\begin{equation}
\label{eq:T}
T = B^T B - \mu^2 I_n = L D L^T ,
\end{equation}
where $\mu$ is a shift variable, $D=diag(d_1,d_2,\cdots,d_n)$ and $L$ is lower bidiagonal matrix, whose diagonal elements are $1$s and one-order subdiagonal elements are $l_{i}, (i=1,\cdots,n-1)$.
%are as below.
%\[ D =  \left( \begin{array}{cccc}
%d_{1} & 0     & \cdots & 0 \\
%0     & d_{2} & \cdots & 0 \\
%\vdots& \vdots& \ddots & \vdots \\
%    0 & 0     & \cdots & d_{n} \end{array} \right), \;\;\;\;
% L =  \left( \begin{array}{ccccc}
%     1&      &       &        &  \\
% l_{1}& 1    &       & 0      &  \\
%      & l_{2}& \ddots&        &  \\
%      & 0    & \ddots& \ddots &  \\
%      &      &       & l_{n-1}& 1
%\end{array} \right) \label{eq:l} \]
By substituting $L$ and $D$ into Eq. (\ref{eq:T}), we can get the following equations
\[ \left \{ \begin{aligned}
b_{1,1}^2 - \mu^2 &= d_1\\
b_{k-1,k-1} b_{k-1,k} &= d_{k-1} l_{k-1}\\
b_{k-1,k}^2 + b_{k,k}^2 - \mu^2 &= l_{k-1}^2 d_{k-1} + d_k
\end{aligned} \right . \label{eq:ldl} \]
where $k = 2,3,\cdots,n$.
Next, we define an auxiliary values $t_{k} = t_{k-1} * (b_{k-1,k}^2 / d_{k-1}) - \mu^2$, and then all the equations in Eq. (\ref{eq:ldl}) reduce to
\begin{equation}
\left \{
\begin{aligned}
d_1 = b_{1,1}^2 - \mu^2 \\
d_k = b_{k,k}^2 + t_{k}
\end{aligned}
\right .
\label{eq:negcount}
\end{equation}

Matrices $D$ and $T$ are two congruent symmetric matrices.
According to the Sylvester's law of inertia, both matrices $D$ and $T$ have the same numbers of positive, negative, and zero eigenvalues.
Thus, the number of negative elements in the diagonal of matrix $D$ is the number of singular values of matrix $T$.
We define a function denoted by $NegCount(\mu)$ to count the number of negative elements in the diagonal of matrix $D$. %described in Algorithm \ref{alg:negcount}.
%Algorithm \ref{alg:negcount} describes how $NegCount$ function works.
%Lines 3-7 calculate the negative number of singular values that are less than $\mu$.
%Since matrices $B$ and $B^T$ have the same singular values,
$NegCount(\mu)$ is also the number of the singular values of $B$ which are less than $\mu$.
$NegCount(x)$ is a monotonically non-decreasing function of $x$ \cite{95ETNAbisecion}.
%If floating point arithmetic is monotonic, then $NegCount(x)$ is a monotonically non-decreasing function of $x$ \cite{95ETNAbisecion}.
% \input{algorithm_negcount}

%Algorithm \ref{alg:negcount} is used to count the number of singular values of matrix $B$ those are less than $\mu$.
%From the algorithm, the number of singular values in an arbitrary interval $[\mu_1,\mu_2)$ are $c_{\mu_2} - c_{\mu_1}$.
%Algorithm \ref{alg:bisection} is the bisection algorithm for calculating the singular values in interval $[l,u)$. Based on the definition of $NegCount$ the total number of singular values in $[l,u)$ is $n_u - n_l = NegCount(u) - NegCount(l)$.
%Lines 5-17 can be parallelized in bisection algorithm.
%In our implementation, we parallelize Line 5-17 of the bisection algorithm. 
%\input{algorithm_bisection}

%\subsubsection{Weak Data Dependency of Bisection Algorithm}
%~
%The efficiency of our algorithm is based on the assumption that the data dependencies for both separating and calculating phases are weak so that we could divide the big problem into smaller but loosely coupled components. Since the singular values are all positive, we assume that the boundary containing all the singular values is $[0, ug)$, where the upper bound $ug$ can be calculated by Gershgorin circle theorem\cite{gershgorin}.
%
%After obtaining the boundary, we divide the interval $[0,ug)$ into $p$ subintervals, and each subinterval $[l_i,u_i)$ can be calculated as follows:
%\begin{eqnarray}
%l_i &=& (ug/p) * (i-1)\\
%u_i &=& (ug/p) * i ,
%\end{eqnarray}
%where $i = 1, 2, \cdots, p$. Then we can calculate the numbers of singular values $n_{l_i}$ and $n_{u_i}$ that are less than $l_i$ and $u_i$ as follows, respectively:
%\begin{eqnarray}
% n_{l_i} = NegCount(l_i) \\
% n_{u_i} = NegCount(u_i) .
%\end{eqnarray}
%$n_{u_i} - n_{l_i}$ is the number of singular values in interval $[l_i,u_i)$ and $n_l, n_l+1, ..., n_u-1$ are the indices of these singular values. 
%The interval can be divided 
%We thus illustrate that the data dependence is weak when dividing the interval
%to subintervals.
%
%Now, we show that the data dependency in bisection algorithm is also weak in the calculation phase (Algorithm \ref{alg:bisection}).
%Suppose $[l,u)$ is an subinterval containing several singular values of a matrix.
%$n_l$ and $n_u$ are the numbers of singular values that are less than $l$ and $u$, respectively.
%How is the bisection algorithm able to calculate an arbitrary singular value $v$ with index $(n_l+k)$ in an subinterval $[l,u)$?
%After several bisection iterations, the subinterval $[l,u)$ reduces to $[v_1,v_1+\tau)$, whose $NegCount$ are $(n_l+k-1)$ and $(n_l+k)$, respectively.
%Since $v$ is in the subinterval $[v_1,v_1+\tau)$, we know that $| v_1 - v | < \tau$, and if $\tau$ is small enough, we stop the iteration and take $v_1$ as calculated singular value with index $(n_l+k)$.
%The whole procedure of bisection algorithm requires only $NegCount$ function without the information of other singular values.
%
%\subsubsection{Error Analysis}
%~
%
%In theory, the bisection algorithm is bound to the upper limit of error between actual value and calculating value, which can be set according to particular applications. 
%The selection of an error tolerance $\tau$ greatly impacts the execution time of the algorithm. 
%Large error tolerance will allow us to solve the problem quick but result in low accuracy.
%On the other hand, too small value for $\tau$ may fail to reach the required accuracy.
%Based on our tests, we can obtain the singular values with error tolerance less than $10^{-16}$.

\vspace{-0.1in}
\subsection{Twisted Algorithm}
\vspace{-0.1in}
%The second phase of our algorithm, twisted algorithm, calculates the corresponding singular vectors.
%It has advantages over existing approaches such as the power method\cite{08power}, which can only find the largest singular value and the corresponding singular vector, and inverse iteration\cite{11iterative}, which does not guarantee the accuracy and orthognality of the singular vectors when the singular values are clustered. In contrast, the twisted algorithm can calculate  orthogonal singular vectors with adequate accuracy \cite{09NLAAtwisted}. 

Suppose $\lambda$ is a singular value of bidiagonal matrix $B \in R^{n \times n}$.
Then the matrix $B^T B - \lambda^2 I$ can be decomposed as
\begin{equation}
B^T B - \lambda^2 I_n = L D_L L^T = U D_U U^T ,
\end{equation}
where $D_L=diag(\alpha_1, \cdots, \alpha_n)$, $D_U = diag(\beta_1, \cdots, \beta_n)$, 
$L$ is lower bidiagonal matrix, whose diagonal elements are $1$s and one-order subdiagonal are $l_{i}, (i=1,\cdots,n-1)$ ($L$ share the same format as in Eq. (\ref{eq:T})).
$U$ is upper bidiagonal matrix, whose diagonal elements are $1$s and one-order superdiagonal are $u_{i}, (i=1,\cdots,n-1)$. 
%\[ L =  \left( \begin{array}{ccccc}
%     1&      &       &        &  \\
% l_{1}& 1    &       & 0      &  \\
%      & l_{2}& \ddots&        &  \\
%      & 0    & \ddots& \ddots &  \\
%      &      &       & l_{n-1}& 1
%\end{array} \right), \;\;\;\;
% U =  \left( \begin{array}{ccccc}
%  1 & u_{1}&       &       &  \\
%    & 1    & u_{2} & 0     &  \\
%    &      & 1     & \ddots&  \\
%    & 0    &       & \ddots& u_{n-1} \\
%    &      &       &       & 1
% \end{array} \right) \]
%$L$ is left bidiagonal matrix, $U$ is upper bidiagonal matrix.
%The diagonal elements in $L$ and $U$ are 1s.
%The subdiagonal elements are $l_k$ in $L$, and the superdiagonal elements are $u_k$ in $U$, separately.

Given the $LDL^T$ and $UDU^T$ decomposition, the twisted factorization of the shifted matrix is shown as
\begin{equation}
B^T B - \lambda^2 I = N_k D_k N_k^T ,
\label{eq:twisted}
\end{equation}
%in Eq. (\ref{eq:gamma}).
%\begin{equation}
%\label{eq:gamma}
%k = \arg \min_{1\le i \le n} \gamma_{i} =
%\begin{cases}
%\beta_1 & \text{if } i=1 \\
%\beta_i - \alpha_i * l_{i-1} & \text{if } 2\le i\le n-1\\
%\alpha_n & \text{if } i=n
%\end{cases}
%\end{equation}
where $D_k$ is diagonal matrix, $N_k$ is a twisted combination of the partial lower triangular $L$ and the partial upper triangular $U$.
The subscript $k = \arg \min \gamma$, and $\gamma = (\beta_1, \beta_2 - \alpha_2 * l_1, \cdots, \beta_i - \alpha_i * l_{i-1}, \cdots, \beta_{n-1} - \alpha_{n-1} * l_{n-2}, \alpha_n)$.
%\begin{equation}
%N_k =  \left( \begin{array}{cccccccc}
% 1& & & & & & & \\
% l_{1}& \ddots& & & & 0& & \\
% & \ddots& 1& & & & &  \\
% & & l_{k-2}& 1 & & & & \\
% & & & \eta_k& 1& u_k& & \\
% & & & & & 1& \ddots& \\
% & & 0& & & & \ddots& u_{n-1}\\
% & & & & & & & 1 \end{array} \right)
%\end{equation}
%\begin{equation}
%\eta_k = \begin{cases}
%0 & \text{if } i=1 \\
%\frac{l_{k-1}\alpha_{k-1}}{(\alpha_{k-1} - v_{k-1}^2 \beta_{k+1})} & \text{if } 2\le i\le n-1\\
%\l_{n-1} & \text{if } i=n
%\end{cases}
%\end{equation}

Thus, the corresponding singular vector of $\lambda$ can be obtained by solving the following matrix equations and then normalizing the solution:
\begin{equation}
\label{eq:unnorm}
N_k^T Z_k = e_k ,
\end{equation}
 where each column in matrix $z_k$ is the non-normalization solution of singular vector corresponding to $\lambda$, and $e_k$ is a $k$th unit vector.

%One advantage of BT algorithm is that it can be applied to cases where singular values are clustered together.
%\textcolor{red}{
Suppose $m$ is the multiplicity of singular values of matrix $B$. 
The algorithm selects the indices of the first $m$ minimum values of $\gamma$. %(May need some more clarification????)} 
Each index $k$ in $m$ has a different twisted factorization, and thus the singular vector can be obtained by solving its own Eq. (\ref{eq:unnorm}). These singular vectors are also orthogonal to each others\cite{09NLAAtwisted}.
%\input{algorithm_twisted}
%Algorithm \ref{alg:twisted} is the algorithm to obtain the corresponding singular vectors of given singular values.
%Lines 4-7 are two obtain the parameter $\gamma$.
%Obtain the multiplicity of a singular value and their corresponding minimum values are described in Lines 8-9.
%Lines 10-16 are to calculate the singular vectors and normalize them.
%%We completely parallelize the twisted factorization to speed up the algorithm on GPU architecture.
%The cost for every singular vector transformation is $O(n)$, and the total cost of the transformations is $O(n^2)$.

